\subsection{Linear Mappings}

\begin{tcolorbox}[title=Problem 2, breakable]
    Let $T$ be a set, $V = \mathcal{F}(T, \mathbb{R})$ the vector space
    of all functions $x : T \longrightarrow \mathbb{R}$
    (Example 1.3.4). Fix a point $t \in T$ and define 
    $f : V \longrightarrow \mathbb{R}$ by the formula 
    $f(x) = x(t)$. Then $f$ is a linear form on $V$.
\end{tcolorbox}

\begin{proof}
    Let $x, y \in V$ and $c \in \mathbb{R}$.  
    Then $f(x + y) = (x + y)(t) = x(t) + y(t) = f(x) + f(y)$.
    and $f(c x) = (c x)(t) = c \, x(t) = c f(x)$.
    Thus $f$ is a linear mapping. 
    Since it maps functions in $V$ to scalars in $\mathbb{R}$ it is a linear form.
\end{proof}

\begin{tcolorbox}[title=Problem 3, breakable]
    If $T : V \longrightarrow W$ is a linear mapping, then $T(x - y) = Tx - Ty$
        for all $x, y \in V$.
\end{tcolorbox}

\begin{proof}
    Suppose $T : V \longrightarrow W$ is a linear mapping.
    Let $x, y$ be arbitrary elements in $V$.
    Then $T(x - y) = T(x + (-y)) = Tx + T(-y) = Tx + (-T(y)) = Tx - Ty$.
\end{proof}

\begin{tcolorbox}[title=Problem 4, breakable]
    If $V$ is a vector space, prove that the mapping $T : V \times V \longrightarrow V$
    defined by $T(x, y) = x - y$ is linear. (It is understood that $V \times V$ has the product 
    vector space structure described in Example 1.3.10.)
\end{tcolorbox}

\begin{proof}
    Suppse $V$ is a vector space.
    Let $(x, y), (a, b)$ be arbitrary elements in $V \times V$.
    Let $c \in \mathbb{R}$ be a scalar.  
    Then $T((x, y) + (a, b)) = T(x + a, y + b) = (x + a) - (y + b) = (x - y) + (a - b) = T(x, y) + T(a, b)$.
    Also $T(c(x, y)) = T(cx, cy) = cx - cy = c(x - y) = c \, T(x, y)$.
    Thus $T$ is linear.
\end{proof}

\begin{tcolorbox}[title=Problem 5, breakable]
    With notations as in Theorem 2.1.3, an element $(a_1, \ldots, a_n)$ of $F^n$
    such that $T(a_1, \ldots, a_n) = \theta$ is called a (linear) \emph{relation}
    among the vectors $x_1, \ldots, x_n$. 
    For example, suppose that $V = F^2, n = 3$ and $x_1 = (2, -3), x_2 = (4, 1), x_3 = (8, 9)$.
    \begin{enumerate}
        \item Find a formula for the linear mapping $F^3 \longrightarrow F^2$ defined in Theorem 2.1.3.
        \item Show that $(-2, 3, 1)$ is a relation among $x_1, x_2, x_3$.
    \end{enumerate}
\end{tcolorbox}

\textbf{Solution (a):}
\[f(a_1, a_2, a_3) = a_1 x_1 + a_2 x_2 + a_3 x_3\]

\textbf{Solution (b):}
\[f(-2, 3, -1) = -2 x_1 + 3 x_2 - x_3 = -2(2, -3) + 3(4, 1) - (8, 9) = (-4, 6) + (12, 3) - (8, 9) = (8, 9) - (8, 9) = (0, 0) = \theta\]

\begin{tcolorbox}[title=Problem 6, breakable]
    The proof of Theorem 2.1.2 uses only the additivity of the mapping $T$.
    Give a proof using only its homogeneity. [Hint: Corollaries 1.4.3, 1.4.5]
\end{tcolorbox}

\begin{theorem}
    If $T : V \longrightarrow W$ is a linear mapping, then $T \theta = \theta$
        and $T(-x) = -(Tx)$ for all $x \in V$.
\end{theorem}

\begin{proof}
    Suppose $T : V \longrightarrow W$ is a linear mapping.
    Then $T(\theta) = T(0 \cdot x) = 0 \cdot T(x)$.
    Then by Corollary 1.4.3, $0 \cdot T(x) = \theta$, hence $T(\theta) = \theta$.
    Also $T(-x) = T((-1)\cdot x) = (-1)T(x)$.
    Then by Corollary 1.4.5, $(-1)T(x) = -T(x)$.
    Thus $T(-x) = -Tx$.
\end{proof}

\begin{tcolorbox}[title=Problem 7, breakable]
    If $\mathcal{D}$ is the vector space of real polynomial functions (Example 1.3.5)
    and $f : \mathcal{D} \longrightarrow \mathbb{R}$ is the mapping defined by 
    $f(p) = p'(1)$ (the value of the derivative of $p$ at $1$), then $f$ is a linear 
    form on $\mathcal{D}$. What is the geometric meaning of $f(p) = 0$.
\end{tcolorbox}

\begin{proof}
    Let $x, y \in \mathcal{D}$ and $c \in \mathbb{R}$.
    Then $f(x + y) = (x + y)'(1) = x'(1) + y'(1) = f(x) + f(y)$.
    and $f(cx) = (cx)'(1) = c\, x'(1) = c f(x)$.
    It follows that $f$ is a linear form on $\mathcal{D}$.
\end{proof}

\textbf{Solution:} $f(p) = 0$ is a critical point at the value $x = 1$ of the function $p$.

\begin{tcolorbox}[title=Problem 8, breakable]
    Let $S : \mathcal{D} \longrightarrow \mathcal{D}$ be the linear mapping of Example 2.1.5.
    Define $R : \mathcal{D} \longrightarrow \mathcal{D}$ by $Rp = Sp + p(5)1$, where $p(5)1$ is the 
    constant function defined by the real number $p(5)$. Then $R$ is linear and 
    $(Rp)' = p$. [So to speak, the constant of integration can be tailor-made for $p$ in a linear fashion.]
    More generally, look at the mapping $Rp = Sp + f(p)1$, where $f$ is any linear form on $\mathcal{D}$.
\end{tcolorbox}

\begin{proof}
    Let $x, y \in \mathcal{D}$ and $c \in \mathbb{R}$.
    Then $R(x + y) = S(x + y) + (x + y)(5)1 = S(x) + S(y) + x(5)1 + y(5)1 = R(x) + R(y)$.
    Also $R(cx) = S(cx) + (cx)(5)1 = c S(x) + c x(5)1 = c R(x)$.
    Thus $R$ is linear.
    
    For the general form 
        notice $R(x + y) = S(x + y) + f(x + y)1 = S(x) + S(y) + f(x)1 + f(y)1 = R(x) + R(y)$.
    Also $R(c x) = S(c x) + f(c x)1 = c S(x) + c f(x)1 = c R(x)$.
\end{proof}

\subsection{Linear Mappings and Linear Subspaces: Kernel and Range}

\begin{tcolorbox}[title=Problem 2, breakable]
    Let $V$ be a vector space over $F$, $f : V \longrightarrow F$ a linear form on $V$ 
        (Definition 2.1.11). Assume that $f$ is not identically zero and choose a vector $y$ 
        such that $f(y) \ne 0$. 
    Let $N$ be the kernel of $f$. Prove that every vector $x$ in $V$ may be written $x = z + cy$
        with $z \in N$ and $c \in F$, and that $z$ and $c$ are uniquely determined by $x$.
    [Hint: If $x \in V$, compute the value of $f$ at the vector $x - [f(x)/f(y)]y$.]
\end{tcolorbox}

\begin{proof}
    Suppose $x, y \in V$.  
    Notice $f\Big(x - \frac{f(x)}{f(y)} y\Big) = f(x) - f\Big(\frac{f(x)}{f(y)} y\Big) = f(x) - \frac{f(x)}{f(y)} f(y) = f(x) - f(x) = 0$.  
    We've just shown $x - \frac{f(x)}{f(y)} y \in \ker(f)$.  
    Thus $x = \Big(x - \frac{f(x)}{f(y)} y\Big) + \frac{f(x)}{f(y)} y$.  
    Let $z = x - \frac{f(x)}{f(y)} y$ and $c = \frac{f(x)}{f(y)}$, and we see $x = z + cy$ as required.

    Suppose $x = z' + c'y$ with $z' \in \ker(f)$ and $c' \in F$.  
    Then $z + cy = z' + c'y \implies z - z' = (c' - c)y$.  
    Applying $f$ gives $0 = f(z - z') = (c' - c) f(y)$, so $c' - c = 0$ since $f(y) \ne 0$.  
    Thus $c' = c$ and $z' = z$.
\end{proof}

\begin{tcolorbox}[title=Problem 3, breakable]
    Let $S : V \longrightarrow W$ and $T : V \longrightarrow W$ be a linear mappings and let 
    $M = \{x \in V \mid Sx \in T(V)\}$. Prove that $M$ is a linear subspace of $V$.
\end{tcolorbox}

\begin{proof} 
    Let $x, y \in M$ and let $c$ be a scalar of the vector space $V$. 
    Since $x,y \in M$, we have $Sx \in T(V)$ and $Sy \in T(V)$. 
    Since $T(V)$ is a linear subspace of $W$ it follows that $S(x + y) = Sx + Sy \in T(V)$.
    Thus $x + y \in M$. 
    Similarly $S(cx) = cS(x) \in T(V)$ thus $cx \in M$. 
    Therefore $M$ is a linear subspace of $V$. 
\end{proof}

\begin{tcolorbox}[title=Problem 4, breakable]
    If $T : V \times V \longrightarrow V$ is the linear mapping 
    $T(x, y) = x - y$ (2.1, Exercise 4), determine the kernel and range of $T$.
\end{tcolorbox}

\textbf{Solution:} The kernel is $(x, x) \in V \times V$ and the range is $V$.

\begin{tcolorbox}[title=Problem 5, breakable]
    Let $V$ be a real vector space, $W$ its complexification (1.3, Exercise 4);
    write $W_R$ for $W$ regarded as a real vector space (1.3, Exercise 3).
    For $(x, y) \in W$, we have 
    \[(x, y) = (x, \theta) + (\theta, y) = (x, \theta) + i(y, \theta).\]
    Prove that $x \mapsto (x, \theta)$ is an injective mapping $V \longrightarrow W_R$.
    [Identifying $x \in V$ with $(x, \theta) \in W$, one can suggestively write 
    $W = V + iV$; so to speak, $V$ is the `real part' of its complexification.]
\end{tcolorbox}

\begin{proof}
    \[x(x_1) = x(x_2) \iff (x_1, 0) = (x_2, 0) \iff x_1 = x_2\]
\end{proof}

\begin{tcolorbox}[title=Problem 6, breakable]
    Let $\mathcal{D}$ be the vector space of real polynomial functions (1.3.5)
    and let $T : \mathcal{D} \longrightarrow \mathcal{D}$ be the linear mapping 
    defined by $Tp = p - p'$, where $p'$ is the derivative of $p$.
    Prove that $T$ is injective.
\end{tcolorbox}

\begin{proof}
    Suppose $x, y \in \mathcal{D}$ such that $T(x) = T(y)$.
    Then $T(x) = T(y) \iff x - x' = y - y' \iff (x - y) - (x' - y') = 0$.
    Let $q = x - y$ then $q - q' = 0 \iff q = q'$.
    Thus $q = 0$ and it follows that $x = y$ and $x' = y'$.
\end{proof}

\subsection{Spaces of Linear Mappings: $\mathcal{L}(V, W)$ and $\mathcal{L}(V)$}

\begin{tcolorbox}[title=Problem 1, breakable]
    Complete the details in the proof of Theorem 2.3.11.
\end{tcolorbox}

\begin{theorem}
    If $V$ and $W$ are vector spaces over $F$, then 
    $\mathcal{L}(V, W)$ is also a vector space over $F$ 
    for the operations defined in 2.3.9.
\end{theorem}

\begin{proof}
    Let $S,T \in \mathcal{L}(V,W)$ and let $a,b \in F$.
    For all $x \in V$, $(a(S+T))(x)
        = a((S+T)(x))
        = a(S(x)+T(x))
        = aS(x)+aT(x)
        = (aS+aT)(x)$.
    For all $x \in V$, $((a+b)T)(x)
        = (a+b)T(x)
        = aT(x)+bT(x)
        = (aT+bT)(x)$.
    For all $x \in V$, $((ab)T)(x)
        = ab\,T(x)
        = a(bT(x))
        = (a(bT))(x)$.
    For all $x \in V$,
        $(1T)(x)=1\cdot T(x)=T(x)$.
\end{proof}

\begin{tcolorbox}[title=Problem 2, breakable]
    Let $V$ be a vector space. If $R, S, T \in \mathcal{L}(V)$ and $c$
        is a scalar, the following equalities are true.
    \begin{enumerate}
        \item $(RS)T = R(ST)$;
        \item $(R + S)T = RT + ST$;
        \item $R(S + T) = RS + RT$;
        \item $(cS)T = c(ST) = S(cT)$;
        \item $TI = T = IT$; ($T$ is the identity mapping)
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    For all $x \in V$.
    \begin{enumerate}
        \item $(RS)T(x) = R(S(T(x))) = R(ST(x)) = (R(ST))(x)$.
        \item $(R + S)T(x)
            = (R + S)(T(x))
            = R(T(x)) + S(T(x))
            = RT(x) + ST(x)
            = (RT + ST)(x)$.
        \item $R(S + T)(x)
            = R(S(x) + T(x))
            = R(S(x)) + R(T(x))
            = RS(x) + RT(x)
            = (RS + RT)(x)$.
        \item $(cS)T(x)
            = cS(T(x))
            = c(ST(x))
            = (c(ST))(x)
            = S(cT)(x)$.
        \item $TI(x) = T(I(x)) = T(x)$ and $IT(x) = I(T(x)) = T(x)$.
    \end{enumerate}
\end{proof}

\begin{tcolorbox}[title=Problem 4, breakable]
    If $T : V \longrightarrow W$ is a linear mapping and $g$
    is a linear form on $W$, show that the formula 
    $f(x) = g(Tx)$ defines a linear form $f$ on $V$.
    [Shortcut: $f = gT = g \circ T$.] The formula 
    $T'g = f$ defines a mapping $T' : \mathcal{L}(W, F) \longrightarrow \mathcal{L}(V, F)$,
    where $F$ is the field of scalars. Show that $T'$ is linear.
    [$T'$ is called the \emph{transpose} (or `adjoint' of $T$.)]
\end{tcolorbox}

\begin{proof}
    By Theorem $2.3.13$ it directly follows that $f$ is linear.

    Let $x, y \in \mathcal{L}(W, F)$ and $c$ be a scalar in $F$. Then for all $v \in V$,
        $T'(x + y)(v) = (x + y)(T(v)) = x(T(v)) + y(T(v)) = T'(x)(v) + T'(y)(v)$.
    Similarly, $T'(c x)(v) = (c x)(T(v)) = c\, x(T(v)) = c\, T'(x)(v)$.
    Therefore, $T'$ is linear.
\end{proof}

\begin{tcolorbox}[title=Problem 5, breakable]
    If $V$ is a vector space over $F$, the vector space 
    $\mathcal{L}(V, F)$ of linear forms on $V$ is called the \emph{dual 
    space} of $V$ and is denoted $V'$.
    Thus, the correspondence $T \mapsto T'$ described in 
    Exercise 4 defines a mapping $\mathcal{L}(V, W) \longrightarrow \mathcal{L}(W', V')$.
    Show that this mapping is linear, that is, $(S + T)' = S' + T'$ and $(cT)' = cT'$
    for all $S, T$ in $\mathcal{L}(V, W)$ and all scalars $c$.
\end{tcolorbox}

\begin{proof}
    Let $S, T \in \mathcal{L}(V, W)$ and let $c$ be a scalar.
    Let $v$ be a vector in $V$.
    Then $(S + T)'g(v) = g(S + T)(v) = g(S(v) + T(v)) = gS(v) + gT(v) = S'g(v) + T'g(v)$.
    Similarly $(cT)'g(v) = g(cT(v)) = cgT(v) = c(T'g)(v)$.
    Thus the correspondence $T \mapsto T'$ is linear.
\end{proof}

\begin{tcolorbox}[title=Problem 6, breakable]
    With notations as in Exercise 4, prove that if $T$
    is surjective then $T'$ is injective; in other words,
    show that if $T(V) = W$ then $T'g = 0 \implies g = 0$.
\end{tcolorbox}

\begin{proof}
    Suppose $T(V) = W$ and $T'g = 0$.
    Let $v \in V$ then $(T'g)(v) = g(T(v)) = 0$ for all $v \in V$.
    Thus $g = 0$ and $T'$ is injective. 
\end{proof}

\begin{tcolorbox}[title=Problem 7, breakable]
    As in Example 2.1.4, let $V = \mathcal{D}$ be the real vector 
    space of all polynomial functions $p : \mathbb{R} \longrightarrow \mathbb{R}$,
    $D : V \longrightarrow V$ the linear mapping defined by $Dp = p'$
    (the derivative of $p$); let $D' : V' \longrightarrow V'$
    be the transpose of $D$ as defined in Exericise 4.
    (Caution: The prime is being used with three different meanings.)

    For each $t \in \mathbb{R}$ let $\rho_i$ be the linear form on $V$ 
    defined by $\rho_t(p) = p(t)$. Let $[a, b]$ be a closed interval on $\mathbb{R}$
    and let $\rho$ be the linear form on $V$ defined by 
    \[\rho(p) = \int_a^b p(t) dt\]
    Prove : $D' \rho = \rho_b - \rho_a$.
    [Hint: Fundamental Theorem of Calculus.]
\end{tcolorbox}

\begin{proof}
    Let $p \in V$.
    Notice $(D'\rho)(p) = \rho(Dp) = \int_a^b p'(t) dt = p(b) - p(a) = \rho_b(p) - \rho_a(p)$.
\end{proof}

\begin{tcolorbox}[title=Problem 9, breakable]
    Let $U, V, W$ be vector spaces over $F$. Prove:
    \begin{enumerate}
        \item For fixed $T \in \mathcal{L}(U, V)$, $\psi = S \mapsto ST$ is a linear mapping 
              $\mathcal{L}(V, W) \longrightarrow \mathcal{L}(U, W)$ (see Figure 8 2.3.12).
        \item For fixed $S \in \mathcal{L}(V, W)$, $\phi = T \mapsto ST$ is a mapping $\mathcal{L}(U, V)
                \longrightarrow \mathcal{L}(U, W)$.
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    Let $x, y \in \mathcal{L}(V, W)$ and $v \in U$. Let $c$ be a scalar.
    Then $(\psi(x + y))(v) = ((x + y)T)(v) = (x + y)(T(v)) = xT(v) + yT(v) = \psi(x)(v) + \psi(y)(v)$.
    Also $(\psi(cx))(v) = ((cx)T)(v) = (cx)(T(v)) = c(xT(v)) = c\psi(x)(v)$.
    Thus $\psi$ is a linear mapping.
\end{proof}

\begin{proof}
    Let $x, y \in \mathcal{L}(U, V)$ and $v \in U$. Let $c$ be a scalar.
    Then $(\phi(x + y))(v) = S(x + y)(v) = S(x(v) + y(v)) = S(x(v)) + S(y(v)) = \phi(x)(v) + \phi(y)(v)$.
    Also $(\phi(cx))(v) = S(cx(v)) = c\,S(x(v)) = c\,\phi(x)(v)$.
    Thus $\phi$ is a linear mapping.
\end{proof}

\begin{tcolorbox}[title=Problem 10, breakable]
    If $T : U \longrightarrow V$ and $S : V \longrightarrow W$ are linear mappings,
    prove that $Im(ST) \subset Im S$ and $Ker(ST) \supset Ker T$.
\end{tcolorbox}

\begin{proof}
    Clearly $T$ can only restrict the domain of $S$ thus $Im(ST) \subset Im S$.
    Clearly any $x$ in $Ker T$ will be in $Ker(ST)$ since $S(0) = 0$.
\end{proof}

\begin{tcolorbox}[title=Problem 11, breakable]
    Let $T : V \longrightarrow V$ be a linear mapping such that $Im T \subset Ker (T - I)$,
    where $I$ is the identity mapping (2.3.3). Prove that $T^2 = T$.
    [Recall $T^2 = TT$.]
\end{tcolorbox}

\begin{proof}
    First note that $Ker(T - I) = \{ v \in V \mid (T - I)(v) = 0 \}$.
    For any $v \in V$, 
    $(T - I)(v) = 0 
        \iff T(v) - I(v) = 0 
        \iff T(v) - v = 0 
        \iff T(v) = v$.
    Let $v \in V$ be arbitrary. Then $T(v) \in Im\, T$.
    Since $Im\, T \subset Ker(T - I)$, it follows that $T(v) \in Ker(T - I)$,
    and thus $T(T(v)) = T(v)$.
    Thus $T^2 = T$.
\end{proof}

\begin{tcolorbox}[title=Problem 12, breakable]
    Supose $V = M \oplus N$ in the sense of 1.6, Exercise 12.
    For each $x \in V$, let $x = y + z$ be its unique decomposition with $y \in M,
    z \in N$ and define $Px = y$, $Qx = z$. Prove that $P, Q \in \mathcal{L}(V)$,
    $P^2 = P$, $Q^2 = Q$, $P + Q = I$ and $PQ = QP = 0$.
\end{tcolorbox}

\begin{proof}
    Let $a_1, a_2 \in M$ and $b_1, b_2 \in N$.
    Let $x = a_1 + b_1, y = a_2 + b_2 \in V$.
    Then $P(x + y) = P((a_1 + a_2) + (b_1 + b_2)) = a_1 + a_2  = Px + Py$.
    Also $P(cx) = P(c(a_1 + b_1)) = P(ca_1 + cb_1) = ca_1 = c(Px)$.
    Thus $P \in \mathcal{L}(V)$. The argument that $Q \in \mathcal{L}(V)$ is similar.
\end{proof}

\begin{proof}
    Simply note that $Im P \subset Ker (P - I)$ thus $P^2 = P$.
    The argument that $Q^2 = Q$ is similar.
\end{proof}

\begin{proof}
    Let $a \in M$ and $b \in N$.
    Let $x = a + b$.
    Then $(P + Q)(x) = P(x) + Q(x) = a + b = x$.
    Thus $P + Q = I$.
\end{proof}

\begin{proof}
    Let $a \in M$ and $b \in N$.
    Let $x = a + b$.
    Then $(PQ)(x) = P(Q(x)) = P(Q(a + b)) = P(0 + Q(b)) = 0$.
    The argument for $QP$ is similar.
\end{proof}

\begin{tcolorbox}[title=Problem 13, breakable]
    Let $T : V \longrightarrow V$ be a linear mapping such that $T^2 = T$,
    and let $M = Im T$ and $N = Ker T$. 
    Prove that $M = \{x \in V \mid Tx = x\} = Ker (T - I)$ and that 
    $V = M \oplus N$ in the sense of 1.6, Exercise 12.
\end{tcolorbox}

\begin{proof}
    Notice $x \in M \iff Tx = x \iff Tx - x = 0 \iff Tx - Ix = 0 \iff (T - I)(x) = 0 \iff x \in \ker(T - I)$.

    Let $x \in V$.
    Let $y = Tx \in M$ and $z = x - Tx \in N$.
    Notice
    \[
    T(z) = T(x - Tx) = Tx - T^2 x = Tx - Tx = 0
    \]
    Thus $z \in \ker T = N$.
    Therefore $x = y + z \in M + N$.
    Suppose $x = y_1 + z_1 = y_2 + z_2$ with $y_i \in M, z_i \in N$. Then
    \[
    y_1 - y_2 = z_2 - z_1 \in M \cap N.
    \]
    But then $M \cap N = \{0\}$ because suppose $v \in M \cap N$, then $Tv = v$ and $Tv = 0$, so $v = 0$.
    Thus $V = M \oplus N$.
\end{proof}

\begin{tcolorbox}[title=Problem 14, breakable]
    Find $S, T \in \mathcal{L}(\mathbb{R}^2)$
        such that $ST \ne TS$.
\end{tcolorbox}

\begin{proof}
    Consider the linear maps $S, T \in \mathcal{L}(\mathbb{R}^2)$
    \[
    S(x, y) = (y, 0), \quad T(x, y) = (0, x).
    \]
    Then for any $(x, y) \in \mathbb{R}^2$
    \[
    ST(x, y) = S(T(x, y)) = S(0, x) = (x, 0),
    \]
    \[
    TS(x, y) = T(S(x, y)) = T(y, 0) = (0, y).
    \]
    Thus $ST \ne TS$.
\end{proof}

\begin{tcolorbox}[title=Problem 15, breakable]
    Let $T : U \longrightarrow V$ and $S : V \longrightarrow W$
    be linear mappings. Prove 
    \begin{enumerate}
        \item If $S$ is injective, then $Ker(ST) = Ker(T)$.
        \item If $T$ is surjective, then $Im(ST) = Im S$.
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    Suppose $S$ is injective.
    Let $x$ be an arbitrary element in $U$.
    Suppose $x \in Ker(T)$ thus $T(x) = 0$.
    Then $(ST)(x) = S(T(x)) = S(0) = 0$.
    Thus $x \in Ker(ST)$.
    Suppose $x \in Ker(ST)$ thus $(ST)(x) = 0$.
    Now $S(0) = 0$ and since $S(T(x)) = 0$ and $S$ is injective, $T(x) = 0$ thus $x \in Ker T$.
    It follows that $Ker(ST) = Ker(T)$.
\end{proof}

\begin{proof}
    Suppose $T$ is surjective.
    It follows that $T$ maps onto all elements in the domain of $S$.
    Therefore $Im (ST) = S$.
\end{proof}

\begin{tcolorbox}[title=Problem 16, breakable]
    Let $V$ be a real or complex vector space and let $t \in \mathcal{V}$
        be such that $T^2 = I$. Define 
        \[M = \{x \in V \mid Tx = x\}, \quad N = \{x \in V \mid Tx = -x\}\]
        Prove that $M$ and $N$ are linear subspaces of $V$ such that $V = M \oplus N$.
    [Hint: For every vector $x$, $x = \frac{1}{2}(x + Tx) + \frac{1}{2}(x - Tx)$.]
\end{tcolorbox}

\begin{proof}
    Let $x \in V$ and consider $x = \frac{1}{2}(x + Tx) + \frac{1}{2}(x - Tx)$.
    Let $m = \frac{1}{2}(x + Tx)$ and $n = \frac{1}{2}(x - Tx)$. 
    Then $Tm = \frac{1}{2}(Tx + T^2x) = \frac{1}{2}(Tx + x) = m$ so $m \in M$, 
    and $Tn = \frac{1}{2}(Tx - T^2x) = \frac{1}{2}(Tx - x) = -n$ so $n \in N$. 
    Thus $x = m + n \in M + N$.

    Suppose $v \in M \cap N$.
    Then $Tv = v$ and $Tv = -v$, which implies $v = 0$.
    Thus $M \cap N = \{0\}$.
    It follows that $V = M \oplus N$.
\end{proof}

\begin{tcolorbox}[title=Problem 17, breakable]
    Let $V = \mathcal{F}(\mathbb{R})$ be the real vector space of all functions $x : \mathbb{R} \longrightarrow \mathbb{R}$ (1.3.4).
    For $x \in V$ define $Tx \in V$ by the formula $(Tx)(t) = x(-t)$. Analyze $T$ in the light of Exercise 16.
    [Remember 1.6, Exercise 13]
\end{tcolorbox}

\textbf{Solution: } The set of functions for which $x(t) = x(-t)$, i.e., the even functions, are in $M$. 
The functions for which $x(t) = -x(-t)$, i.e., the odd functions, are in $N$. 
Every function $x \in V$ can be expressed as $x = \frac{1}{2}(x + Tx) + \frac{1}{2}(x - Tx) \in M \oplus N$.

\begin{tcolorbox}[title=Problem 18, breakable]
    Let $T \in \mathcal{L}(U, V)$ and $S \in \mathcal{L}(V, W)$,
        prove that $(ST)' = T'S'$.
    (cf. Exercise 4).
\end{tcolorbox}

\begin{proof}
    Let $f \in W'$ be a linear form on $W$.  
    Then $(ST)'(f) = f \circ (ST) = (f \circ S) \circ T = T'(S'(f))$.
\end{proof}

\begin{tcolorbox}[title=Problem 19, breakable]
    Let $S, T \in \mathcal{L}(V, W)$ and let $M = \{x \in V \mid Sx = Tx\}$.
    Prove that $M$ is a linear subspace of $V$. [Hint: Consider $Ker(S - T)$.]
\end{tcolorbox}

\begin{proof}
    Note that $M = \{x \in V \mid Sx - Tx = 0\} = \{x \in V \mid (S - T)x = 0\} = \ker(S - T)$.
    Since the kernel of a linear map is always a linear subspace, $M$ is a linear subspace of $V$.
\end{proof}

\begin{tcolorbox}[title=Problem 20, breakable]
    If $T : V \longrightarrow W, S : W \longrightarrow V$ are linear mappings
        such that $ST = I$, prove that $Ker T = \{0\}$ and $Im S = V$.
\end{tcolorbox}

\begin{proof}
    Let $x \in Ker T$ such that $Tx = 0$.
    Then $STx = Tx = 0$.
    Since $ST = I$, we have $x = 0$ thus $Kern T = \{0\}$.

    Next, let $v \in V$. Then $v = Iv = STv = S(Tv)$.
    Thus $v \in Im S$. Therefore $Im S = V$.
\end{proof} 

\begin{tcolorbox}[title=Problem 21, breakable]
    If $V = \{\theta\}$ or $W = \{\theta\}$ then $\mathcal{L}(V, W) = \{0\}$.
    If $V \ne \{\theta\}$ then $I_v \ne 0$.
\end{tcolorbox}

\begin{proof}
    Suppose $V = \{\theta\}$ or $W = \{\theta\}$.
    Clearly there is only one linear mapping between $V$ and $W$
    which is for all $x \in V$, $T(x) = 0 \in W$.

    Suppose $V \ne \{\theta\}$. $V$ has at least two elements,
    one of which maps to $0$.
    The other must map to a nonzero element under $I_V$.
\end{proof}

\begin{tcolorbox}[title=Problem 22, breakable]
    A lightning proof of Theorem 2.3.11 can be based on an earlier exercise:
    Since $0 \in \mathcal{L}(V, W)$, Lemma 2.3.10 shows that $\mathcal{V, W}$
    is a linear subspace of the vector space $\mathcal{F}(V, W)$ defined as in 
    1.3, Exercise 1, therefore $\mathcal{L}(V, W)$ is also a vector space (1.6.2).
\end{tcolorbox}

\textbf{Solution:} OK.

\begin{tcolorbox}[title=Problem 23, breakable]
    If $T : U \longrightarrow V$ and $S : V \longrightarrow W$
        are linear mappings, prove that $Ker(ST) = T^{-1}(Ker S)$.
\end{tcolorbox}

\begin{proof}
    Let $x \in U$. Then
    \[
        x \in Ker(ST)
        \iff STx = 0
        \iff S(Tx) = 0
        \iff Tx \in Ker S
        \iff x \in T^{-1}(Ker S).
    \]
    Therefore $Ker(ST) = T^{-1}(Ker S)$.
\end{proof}

\begin{tcolorbox}[title=Problem 24, breakable]
    Let $V = \mathcal{D}$ be the vector space of real polynomial functions,
    $D : V \longrightarrow V$ the differentiation mapping $Dp = p'$ (2.1.4).
    Let $u$ be the monomial $u(t) = t$ and define another linear mapping 
    $M : V \longrightarrow V$ by the formula $Mp = up$. (So to speak,
    $M$ is multiplication by $t$.) Prove that $DM - MD = I$ (the identity mapping).
    [Hint: The claim is that $(up)' - up' = p$. Remember the `product rule'?]
\end{tcolorbox}

\begin{proof}
    By the product rule,
    \[
        (up)' = u'p + up'.
    \]
    Since $u(t) = t$ we know $u' = 1$. Thus
    \[
        (up)' = p + up'.
    \]
\end{proof}

\begin{tcolorbox}[title=Problem 25, breakable]
    Let $D : \mathcal{D} \longrightarrow \mathcal{D}$ be the differentiating map of Exercise 24
        and let $S : \mathcal{D} \longrightarrow \mathcal{D}$ be the linear mapping such that 
        $(Sp)' = p$ and $(Sp)(0) = 0$ (2.1.5). Prove:
        \begin{enumerate}
            \item If $R : \mathcal{D} \longrightarrow \mathcal{D}$ is any linear mapping such that $(Rp)' = p$ for all $p \in \mathcal{D}$, then $DR = I$.
            \item If $T : \mathcal{D} \longrightarrow \mathcal{D}$ is a linear mapping such that $DT = 0$, then there exists a linear form $f$ on $\mathcal{D}$
                    such that (in the notation of Exercise 2.3.4) $T = f \otimes 1$, where $1$ is the constant function $1$. [Hint: $Im T \subset Ker D$.]
            \item With $R$ as in (i), $R = S + f \otimes 1$ for a suitable linear form $f$ on $\mathcal{D}$. [Hint: Consider $T = R - S$.] Remember $2.1$, Exercise 8?
        \end{enumerate}
\end{tcolorbox}

\begin{proof}
    Suppose $R : \mathcal{D} \longrightarrow \mathcal{D}$ is a linear mapping such that $(Rp)' = p$ for all $p \in \mathcal{D}$.
    Let $p \in \mathcal{D}$. Then $(DR)(p) = D(Rp) = (Rp)' = p$.  
    Thus $DR = I$.
\end{proof}

\begin{proof}
    If $T : \mathcal{D} \longrightarrow \mathcal{D}$ is a linear mapping such that $DT = 0$,  
    then for all $p \in \mathcal{D}$, $Tp$ is a constant function.  
    Thus $T = T \otimes 1$, where $1$ is the constant function $1$.
\end{proof}

\begin{proof}
    Let $R : \mathcal{D} \longrightarrow \mathcal{D}$ and let $T = R - S$.
    Then for any $p \in \mathcal{D}$, $D(Tp) = D((R - S)p) = DR(p) - DS(p) = I(p) - I(p) = 0$.
    Thus $DT = 0$.
    By part (ii), there exists a linear form $f$ on $\mathcal{D}$ such that $T = f \otimes 1$.
    Therefore $R = S + T = S + f \otimes 1$.
\end{proof}

\begin{tcolorbox}[title=Problem 26, breakable]
    Let $S, T \in \mathcal{L}(V)$. If $ST - I$ is injective then so is $TS - I$. [Hint: $S(TS - I) = (ST - I)S$.]
\end{tcolorbox}

\begin{proof}
    Suppose $ST - I$ is injective.
    Thus $\ker (ST - I) = \{0\}$.
    Suppose $x \in V$ such that $(TS - I)(x) = 0$.
    Then applying $S$ we have $S(TS - I)(x) = 0$.
    By the hint we have $((ST - I)S)(x) = 0 \iff (ST - I)(S(x)) = 0$.
    Since $ST - I$ is injective we have $S(x) = 0$.
    Then $(TS - I)(x) = TS(x) - x = T0 - x = -x = 0$.
    Thus $x = 0$.
\end{proof}

\subsection{Isomorphic Vector Spaces}

\begin{tcolorbox}[title=Problem 2, breakable]
    Regard $\mathbb{C}^n$ as a real vector space 
    in the natural way (sums as usual, multiplication 
    only by real scalars); 
    then $\mathbb{C}^n \cong \mathbb{R}^{2n}$
    as real vector spaces.
\end{tcolorbox}

\begin{proof}
    Let $r_1, r_2, \ldots, r_{2n-1}, r_{2n} \in \mathbb{R}$.
    Consider the mapping
    \[
    (r_1, r_2, \ldots, r_{2n-1}, r_{2n})
    \mapsto
    (r_1 + r_2 i, \ldots, r_{2n-1} + r_{2n} i).
    \]
    We know that the map $(r_1, r_2) \mapsto r_1 + r_2 i$ is linear and bijective
    over $\mathbb{R}$.
    Our mapping is simply an extension of this map to $n$ components and is therefore
    linear and bijective.
\end{proof}

\begin{tcolorbox}[title=Problem 3, breakable]
    Let $X$ be a set, $V$ a vector space, $f : X \longrightarrow V$ a bijection.
    There exists a unique vector space structure on $X$ for which $f$ is a linear mapping 
    (hence a vector space isomorphism).
    [Hint: Define sums and scalar multiples in $X$ by the formulas $x + y = f^{-1}(f(x) + f(y)), cx = f^{-1}(cx)$.
    This trick is called `transport of structure'.]
\end{tcolorbox}

\begin{proof}
    Clearly $X$ is a vector space, since after applying $f$ each vector space axiom
    becomes the corresponding axiom in $V$, and injectivity of $f$ implies the axioms
    hold in $X$.
\end{proof}

\begin{tcolorbox}[title=Problem 4, breakable]
    Let $V$ be the set of n-ples $x = (x_1, \ldots, x_n)$
        of real numbers $> 0$, that is, 
    \[V = \{(x_1, \ldots, x_n) \mid x_i \in (0, + \infty \text{ for } i = 1, \ldots, n)\}.\]
    For $x = (x_1, \ldots, x_n), y = (y_1, \ldots, y_n)$ in $V$ and $c \in \mathbb{R}$, define 
    \[x \oplus y  = (x_1 y_1, \ldots, x_n y_n), c \cdot x = (x_1^c, \ldots, x_n^c),\]
    (here $x_i y_i$ and $c_i^c$ are the usual product and power),
    Define a mapping $T : V \longrightarrow \mathbb{R}^n$ by the formula 
    $T(x_1, \ldots, x_n) = (\log x_1, \ldots, \log x_n)$.
    \begin{enumerate}
        \item Show that $T(x \oplus y) = Tx + Ty$ and $T(c \cdot x) = c(Tx)$ for all $x, y$ in $V$ and all $c \in \mathbb{R}$.
        \item True or false (explain): $V$ is a real vector space for the operations $\cdot$.
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    Let $x, y \in V$ and $c$ be a scalar.
    Then
    \[
    T(x \oplus y)
        = T((x_1 y_1, \ldots, x_n y_n))
        = (\log(x_1 y_1), \ldots, \log(x_n y_n))
        = (\log x_1 + \log y_1, \ldots, \log x_n + \log y_n)
    \]
    \[
        = (\log x_1, \ldots, \log x_n) + (\log y_1, \ldots, \log y_n)
        = Tx + Ty.
    \]
    Also,
    \[
    T(c \cdot x)
        = T((x_1^c, \ldots, x_n^c))
        = (\log(x_1^c), \ldots, \log(x_n^c))
        = (c \log x_1, \ldots, c \log x_n)
        = c(Tx).
    \]
\end{proof}

\textbf{Solution: } False since scalar multiplication does not satisfy the vector space axioms.

\begin{tcolorbox}[title=Problem 5, breakable]
    Let $V$ be a vector space, $T \in \mathcal{L}(V)$ bijective, and $c$ a nonzero 
    scalar. Prove that $cT$ is bijective and that $(cT)^{-1} = c^{-1}T^{-1}$.
\end{tcolorbox}

\begin{proof}
    Let $v, v' \in V$ and suppose $cT(v) = cT(v')$.
    Then $cT(v) = cT(v') \iff cT(v) - cT(v') = 0 \iff c(T(v) - T(v')) = 0$.
    Since $c \ne 0$, we must have $T(v) = T(v')$.
    Since $T$ is injective, it follows that $v = v'$.
    Thus $cT$ is injective.

    Let $v \in V$. Since $c \ne 0$, the scalar $\frac{1}{c}$ exists.
    Since $V$ is closed under scalar multiplication, $\frac{1}{c} \cdot v = \frac{v}{c} \in V$.
    Since $T$ is surjective, there exists $x \in V$ such that $T(x) = \frac{v}{c}$.
    Then $cT(x) = c\left(\frac{v}{c}\right) = v$.
    Thus $cT$ is surjective.

    Let $v \in V$, and suppose $(cT)^{-1}(v) = x$. 
    Then $cT(x) = v \implies T(x) = \frac{v}{c} \implies x = T^{-1}\left(\frac{v}{c}\right) = T^{-1}(c^{-1} v)$.
    Thus $(cT)^{-1} = c^{-1}T^{-1}$.
\end{proof}


\begin{tcolorbox}[title=Problem 6, breakable]
    Let $T : V \longrightarrow W$ be a bijective linear mapping.
    For each $S \in \mathcal{L}(V)$, define $\rho : \mathcal{L}(V) \longrightarrow TST^{-1}$
    (note that the product is defined). Prove that $\rho : \mathcal{L}(V) \longrightarrow \mathcal{L}(W)$
    is a bijective linear mapping such that $\rho(RS) = \rho(R)\rho(S)$ for all $R, S \in \mathcal{L}(V)$.
\end{tcolorbox}


\begin{proof}
    Since the composition of linear mappings is linear, $T S T^{-1}$ is a linear mapping.  
    Let $R, S \in \mathcal{L}(V)$. Then
    \[
        \rho(RS) = T (RS) T^{-1} = (T R T^{-1}) (T S T^{-1}) = \rho(R)\rho(S).
    \]
    Suppose $\rho(S)(v) = 0$ for some $v \in W$.
    Then $\rho(S)(v) = 0 \iff TST^{-1}(v) = 0$.
    Now $v = T(x)$ for some $x \in V$ thus $TST^{-1}(T(x)) = TS(x) = 0$.
    Then since $T$ is injective $S(x) = 0$ thus $\rho$ is injective.
    It is surjective because for any $U \in \mathcal{L}(W)$, 
        setting $S = T^{-1} U T$ gives $\rho(S) = U$.
\end{proof}

\begin{tcolorbox}[title=Problem 7, breakable]
    Let $V$ be a vector space, $T \in \mathcal{L}(V)$. Prove:
    \begin{enumerate}
        \item If $T^2 = 0$ then $I - T$ is bijective. 
        \item If $T^n = 0$ for some positive integer $n$, then $I - T$ is bijective.
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    Suppose $T^2 = 0$. Let $v \in V$ and suppose 
    $(I - T)(v) = 0 \implies T(v) - T^2(v) = 0 \implies T(v) = 0$.
    But $I(v) - T(v) = 0 \implies T I(v) - T^2(v) = T(0) \implies v - T(v) = 0 \implies v = T(v)$.
    Thus $v = 0$. It follows that $I - T$ is injective.

    Let $y \in V$. We want to find $x \in V$ such that $(I - T)(x) = y$.
    Let $x = y + T(y)$.
    Then $(I - T)(x) 
        = (I - T)(y + T(y)) 
        = I(y + T(y)) - T(y + T(y)) 
        = I(y) + IT(y) - T(y) - T^2(y) 
        = y + T(y) - T(y)
        = y$.
\end{proof}

\begin{proof}
    We proceed via induction on $n$. The previous proof shows the base case $n = 2$.
    Suppose for some $n-1$, $T^{n-1} = 0$ implies $I - T$ is bijective.
    Now suppose $T^n = 0$.
    Let $v \in V$ and suppose $(I - T)(v) = 0$. 
    Composing with $T^{n - 1}$, we get
        $T^{n-1}(v) - T^n(v) = T^{n-1}(v) = 0$.
    By the induction hypothesis, this implies $v = 0$, so $I - T$ is injective.

    For surjectivity, let $y \in V$ and set 
        $x = y + T(y) + \dots + T^{n-1}(y)$. 
    Then $(I - T)(x) = y$, so $I - T$ is bijective.
\end{proof}

\begin{tcolorbox}[title=Problem 8, breakable]
    Let $U, V, W$ be vector spaces over the same field.
    Form the product vector spaces $U \times V, V \times W$ (Definition 1.3.11),
    then the product vector spaces $(U \times V) \times W$ and $U \times (V \times W)$.
    Prove that $(U \times V) \times W \cong U \times (V \times W)$.
\end{tcolorbox}

\begin{proof}
    Consider the mapping 
    \[
        \rho : (U \times V) \times W \longrightarrow U \times (V \times W), \quad
        \rho((x_1, x_2), x_3) = (x_1, (x_2, x_3)).
    \]

    Suppose $\rho((x_1, x_2), x_3) = \rho((y_1, y_2), y_3)$. 
    Then $(x_1, (x_2, x_3)) = (y_1, (y_2, y_3))$, so $x_1 = y_1$, $x_2 = y_2$, $x_3 = y_3$. 
    Thus $((x_1, x_2), x_3) = ((y_1, y_2), y_3)$, and $\rho$ is injective.

    Let $(u, (v, w)) \in U \times (V \times W)$. 
    Then $\rho((u, v), w) = (u, (v, w))$.
    Thus $\rho$ is surjective.
\end{proof}


\begin{tcolorbox}[title=Problem 9, breakable]
    Prove that $\mathbb{R}^2 \times \mathbb{R}^3 \cong \mathbb{R}^5$.
\end{tcolorbox}

\begin{proof}
    Consider the mapping 
    \[ 
        \rho : \mathbb{R}^2 \times \mathbb{R}^3 \longrightarrow \mathbb{R}^5, \quad 
        \rho(((x_1, x_2), (x_3, x_4, x_5))) = (x_1, x_2, x_3, x_4, x_5)
    \]

    Suppose $\rho(((x_1, x_2), (x_3, x_4, x_5))) = \rho(((y_1, y_2), (y_3, y_4, y_5)))$.
    Then $(x_1, x_2) = (y_1, y_2)$ and $(x_3, x_4, x_5) = (y_3, y_4, y_5)$.
    Thus $((x_1, x_2), (x_3, x_4, x_5)) = ((y_1, y_2), (y_3, y_4, y_5))$, and $\rho$ is injective.

    Let $(x_1, x_2, x_3, x_4, x_5) \in \mathbb{R}^5$.
    Then $\rho(((x_2, x_2), (x_3, x_4, x_5))) = (x_1, x_2, x_3, x_4, x_5)$.
    Thus $\rho$ is surjective.
\end{proof}

\begin{tcolorbox}[title=Problem 10, breakable]
    With notations as in Exercie 8, prove that $V \times W \cong W \times V$.
\end{tcolorbox}

\begin{proof}
    Consider the mapping
    \[
        \rho : V \times W \longrightarrow W \times V, \quad
        \rho((v, w)) = (w, v).
    \]

    Suppose $\rho((v_1, w_1)) = \rho((v_2, w_2))$.
    Then $(w_1, v_1) = (w_2, v_2)$, so $v_1 = v_2$ and $w_1 = w_2$.
    Thus $(v_1, w_1) = (v_2, w_2)$, and $\rho$ is injective.

    Let $(w, v) \in W \times V$.
    Then $\rho((v, w)) = (w, v)$.
    Thus $\rho$ is surjective.
\end{proof}

\begin{tcolorbox}[title=Problem 11, breakable]
    With notations as in Example 2.4.2, prove that $(x_1, x_2) \mapsto (x_1, x_2 + x_2, 0)$
    is an isomorphism $\mathbb{R}^2 \mapsto W$.
\end{tcolorbox}

\begin{proof}
    Consider the mapping
    \[
        \rho : \mathbb{R}^2 \longrightarrow W, \quad
        \rho((x_1, x_2)) = (x_1, x_2, 0).
    \]

    Suppose $\rho((x_1, x_2)) = \rho((y_1, y_2))$.
    Then $(x_1, x_2, 0) = (y_1, y_2, 0)$, so $x_1 = y_1$ and $x_2 = y_2$.
    Thus $(x_1, x_2) = (y_1, y_2)$, and $\rho$ is injective.

    Let $(x_1, x_2, 0) \in W$.
    Then $\rho((x_1, x_2)) = (x_1, x_2, 0)$.
    Thus $\rho$ is surjective.
\end{proof}

\subsection{Equivalence Relations and Quotient Sets}

\begin{tcolorbox}[title=Problem 2, breakable]
    Let $X$ be the set of all \emph{nonzero}
    vectors in $\mathbb{R}^n$, that is,
    $X = \mathbb{R}^n - \{\theta\}$.
    For $x, y$ in $X$, write $x \sim y$
    if $x$ is proportional to $y$, that is,
    if there exists a scalar $c$ (necessarily nonzero)
    such that $x = cy$; this is an equivalence relation 
    in $X$.
\end{tcolorbox}


\begin{proof}
    Notice that $x = 1x$, thus $x \sim x$.

    Suppose $x \sim y$.
    Then $x = cy$ for some scalar $c$.
    Since $c \ne 0$, we have $\frac{1}{c}x = y$.
    Thus $y \sim x$.

    Suppose $x \sim y$ and $y \sim z$.
    Then $x = c_1 y$ and $y = c_2 z$ for some scalars $c_1, c_2$.
    Then $x = c_1 y = c_1(c_2 z) = (c_1 c_2)z$.
    Thus $x \sim z$.
\end{proof}

\begin{tcolorbox}[title=Problem 4, breakable]
    If $\lambda$ is a nonempty set of vector spaces over the field $F$, then the relation 
    of isomorphism (2.4.1) is an equivalence relation in $\lambda$.
\end{tcolorbox}

\begin{proof}
    Let $x, y, z \in \lambda$.
    Notice that $x \sim x$ through the identity mapping.

    Suppose $x \sim y$. Then there exists an isomorphism $\rho$
    such that $\rho(x) = y$. But then $x = \rho^{-1}(y)$,
    thus $y \sim x$.

    Suppose $x \sim y$ and $y \sim z$.
    Then there exist $\rho_1, \rho_2$
    such that $\rho_1(x) = y$ and $\rho_2(y) = z$.
    Then $z = \rho_2(\rho_1(x))$
    Thus $x \sim z$.
\end{proof}

\begin{tcolorbox}[title=Problem 9, breakable]
    Let $f : X \longrightarrow Y$ be any mapping, $x \sim x'$
    the equivalence relation defined by $f(x) = f(x')$ (2.5.1),
    $q : X \longrightarrow X / \sim$ the quotient mapping (2.5.17).
    
    Define a mapping $g : X / \sim \longrightarrow f(X)$ as follows : 
    if $u \in X / \sim$ define $g(u) = f(x)$, where $x$ is any element of $X$
    such that $u = q(x)$. [If also $u = q(x')$ then $x \sim x'$, 
    so $f(x) = f(x')$; thus $g(u)$ depends only on $u$ not on the particular 
    $x$ chosen to represent the class $u$.] Prove (cf. Fig. 10):
    \begin{enumerate}
        \item $g$ is bijective;
        \item $f = i \circ g \circ q$, where $i : f(X) \longrightarrow Y$ is the insertion mapping 
              (Appendix A.3.8).
    \end{enumerate}
    In particular, if $f : X \longrightarrow Y$ is surjective, then $g : X / \sim \longrightarrow Y$ is bijective.
\end{tcolorbox}
\begin{proof}
    Suppose $u, u' \in X / \sim$ such that $g(u) = g(u')$.
    By definition, $g(u) = f(x)$ and $g(u') = f(x')$ for some
    $x, x' \in X$ with $u = q(x)$ and $u' = q(x')$.
    Then $f(x) = f(x')$, so $x \sim x'$.
    Thus $q(x) = q(x')$, and therefore $u = u'$.
    Thus $g$ is injective.

    Let $y$ be an arbitrary element of $f(X)$.
    Then $y = f(x)$ for some $x \in X$.
    Let $u = q(x) \in X / \sim$.
    By definition of $g$, we have $g(u) = f(x) = y$.
    Thus $g$ is surjective.
\end{proof}

\begin{proof}
    Let $x \in X$.
    Then $q(x) \in X/\sim$ and $g(q(x)) = f(x)$ by definition of $g$.
    Since $i : f(X) \to Y$ is the insertion mapping, $i(f(x)) = f(x)$.
    Thus $(i \circ g \circ q)(x) = f(x)$ so $f = i \circ g \circ q$.

    Suppose $f : X \longrightarrow Y$ is surjective.
    Then $f(X) = Y$, so $g : X/\sim \longrightarrow Y$.

    Suppose $u, u' \in X / \sim$ such that $g(u) = g(u')$.
    Then $g(u) = f(x)$ and $g(u') = f(x')$ for some $x, x' \in X$.
    Thus $f(x) = f(x')$, so $x \sim x'$ and thus $u = u'$.
    Thus $g$ is injective.

    Let $y \in Y$.
    Since $f$ is surjective there exists $x \in X$ such that $f(x) = y$.
    Let $u = q(x) \in X/\sim$.
    Then $g(u) = f(x) = y$.
    Thus $g$ is surjective.
\end{proof}


\begin{tcolorbox}[title=Problem 10, breakable]
    For $x, y$ in $\mathbb{R}$, write $x \sim y$ if $x \sim y$ is an integer (that is, $x - y \in \mathbb{Z}$);
    this is an equivalence relation in $\mathbb{R}$. The quotient set is denoted $\mathbb{R} / \mathbb{Z}$; the 
    equivalence class $[x]$ of $x \in \mathbb{R}$ is the set $x + \mathbb{Z} = \{x + n \mid n \in \mathbb{Z}\}$.
    \begin{enumerate}
        \item There is a connection between functions defined on $\mathbb{R} / \mathbb{Z}$ and functions defined 
              on $\mathbb{R}$ that are periodic of period $1$; can you make it precise?
        \item There exists a bijection $g : \mathbb{R} / \mathbb{Z} \longrightarrow U$, where 
                    $U = \{(a, b) \in \mathbb{R}^2 \mid a^2 + b^2 = 1\}$ is the `unit circle' in $\mathbb{R}^2$.
                [Hint: Apply Exercise 9 to the function $f : \mathbb{R} \longrightarrow U$ defined by 
                $f(t) = (\cos 2 \pi t, \sin 2 \pi t)$.]
    \end{enumerate}
\end{tcolorbox}

\textbf{Solution: }
Consider a periodic function of period $1$, say 
$f : \mathbb{R} \longrightarrow \mathbb{R}$.
Then for all $x \in \mathbb{R}$ and all $n \in \mathbb{Z}$,
\[
f(x+n) = f(x).
\]
Thus $f$ takes the same value on all elements of the equivalence class
\[
[x] = x + \mathbb{Z}.
\]
Conversely, any function defined on $\mathbb{R}/\mathbb{Z}$ determines
a function on $\mathbb{R}$ that is periodic of period $1$ by composition
with the quotient map.

\begin{proof}
    Consider the function
    \[
    f : \mathbb{R} \longrightarrow U, \qquad f(t) = (\cos 2\pi t, \sin 2\pi t).
    \]
    Notice that $f(t + n) = f(t)$ for all $n \in \mathbb{Z}$, so $f$ is constant on equivalence classes of $\mathbb{R}/\mathbb{Z}$.
    By Exercise 9 there is a map
    \[
    g : \mathbb{R}/\mathbb{Z} \longrightarrow U, \qquad g([t]) = f(t).
    \]
    Suppose $g([t]) = g([s])$. Then $f(t) = f(s)$ so $t - s \in \mathbb{Z}$. Thus $[t] = [s]$.
    Suppose $(a,b) \in U$. There exists $t \in [0,1)$ such that $(\cos 2\pi t, \sin 2\pi t) = (a,b)$, so $(a,b) = g([t])$.
\end{proof}

\begin{tcolorbox}[title=Problem 11, breakable]
    For $x, y$ in $\mathbb{R}$, write $x \sim y$ if $x - y$ is an integral multiple of $2 \pi$
    (that is, $x - y \in 2 \pi \mathbb{Z}$). With an eye on Exercise 10, discuss periodic functions 
    of period $2 \pi$ and describe a bijection of $\mathbb{R} / 2 \pi \mathbb{Z}$ onto the unit circle $U$.
\end{tcolorbox}

\textbf{Solution: }  
The equivalence class of $x \in \mathbb{R}$ in $\mathbb{R} / 2\pi \mathbb{Z}$ is $[x] = \{ x + 2 \pi n \mid n \in \mathbb{Z} \}$.
A function $f : \mathbb{R} \longrightarrow \mathbb{R}$ is periodic of period $2\pi$ if $f(x + 2 \pi) = f(x)$ for all $x \in \mathbb{R}$.
A bijection of $\mathbb{R}/2\pi \mathbb{Z}$ onto the unit circle $U = \{(a,b) \in \mathbb{R}^2 \mid a^2+b^2 = 1\}$ 
can be defined as
\[
g : \mathbb{R}/2\pi \mathbb{Z} \longrightarrow U, \qquad g([x]) = (\cos x, \sin x),
\]

\subsection{Quotient Vector Spaces}


\begin{tcolorbox}[title=Problem 1, breakable]
    Prove that if $V = M \oplus N$ (1.6, Exercise 12) then $V / M \cong N$.
    [Hint: Restrict the quotient mapping $V \longrightarrow V / M$ to $N$ 
    (Appendix $A.3.8$, and calculate the kernel and range of the restricted mapping.)]
\end{tcolorbox}

\begin{proof}
    Suppose $V = M \oplus N$.
    Let $q : V \longrightarrow V / M$ be the quotient mapping.
    Then consider $(q \mid N) : N \longrightarrow V / M$, which is the restriction 
    of $q$ to $N$.
    It was shown in the proof of Theorem 2.6.1 that $q$ is linear.
    Suppose $x \in N$ such that $(q \mid N)(x) = [0]$.  
    By definition, this means $x \in M$.  
    But $x \in N$ and $V = M \oplus N$ thus $x = 0$.  
    Thus $(q \mid N)$ is injective.
    Let $[y] \in V / M$.  
    Since $V = M \oplus N$ then $y = m + n$ with $m \in M$ and $n \in N$.  
    Then $(q \mid N)(n) = [n] = [m + n] = [y]$.  
    Thus $(q \mid N)$ is surjective.
    Therefore $q \mid N$ is bijective, and it follows that $V / M \cong N$.
\end{proof}

\begin{tcolorbox}[title=Problem 2, breakable]
    Let $M$ and $N$ be linear subspaces of the vector spaces $V$ and $W$,
        respectively.
    Form the product vector space $V \times W$ (Definition 1.3.11).
    Then $M \times N$ is a linear subspace of $V \times W$ and 
    \[(V \times W) / (M \times N) \cong (V / M) \times (W / N).\]
    Prove this by showing that 
    \[(x, y) + M \times N \longrightarrow (x + M, y + N),\]
    defines a function $(V \times W) / (M \times N) \longrightarrow (V / M) \times (W / N)$
    and that this function is linear and bijective. 
    [The essential first step to show that if $u = (x, y) + M \times N = (x', y') + M \times N$,
    then $(x + M, y + N) = (x' + M, y' + N)$, that is, the proposed functional value at $u$ 
    depends only on $u$ and not on the particular ordered pair $(x, y) \in u$ chosen to 
    represent it (cf. the proof of Theorem 2.6.1).]
\end{tcolorbox}

\begin{proof}
    Let $q : (V \times W) / (M \times N) \longrightarrow (V / M) \times (W / N)$ be 
        a mapping defined as 
    \[q((x, y) + M \times N) = (x + M, y + N).\]
    We first show that $q$ is well defined.
    Suppose $u = (x, y) + M \times N = (x', y') + M \times N$.
    Then 
    \[(x, y) - (x', y') \in M \times N.\]
    Thus $(x - x', y - y') = (m, n)$ for some $m \in M$ and $n \in N$.
    Then $x - x' \in M$ and $y - y' \in N$ thus $x + M = x' + M$ and $y + N = y' + N$.
    Thus $(x + M, y + N) = (x' + M, y' + N)$.

    We now show $q$ is additive.
    Let $(x, y), (x', y')$ be elements in $V \times W$.
    Then 
    \[
    q((x, y) + (x', y')) 
    = q((x + x', y + y')) 
    = (x + x' + M, y + y' + N)
    = (x + M, y + N) + (x' + M, y' + N)
    = q((x, y)) + q((x', y')).
    \]

    We now show $q$ is homogeneous.
    \[
    q(c(x, y)) = q((cx, cy)) = (cx + M, cy + N) = c(x + M, y + N) = cq(x, y).
    \]

    We now show $q$ is injective.
    Suppose $q((x, y)) = (0 + M, 0 + N)$. Then $x \in M$ and $y \in N$.
    Thus $(x, y) \in M \times N$ so $(x, y) + M \times N = M \times N$.
    Therefore $(x, y) = 0$ in $(V \times W)/(M \times N)$, and $q$ is injective.

    We now show $q$ is surjective.
    Let $(x + M, y + N)$ be an element in $(V/M) \times (W/N)$.
    Then $q((x, y)) = (x + M, y + N)$, thus $q$ is surjective.
\end{proof}


\begin{tcolorbox}[title=Problem 3, breakable]
    Let $f : \mathbb{R}^3 \longrightarrow \mathbb{R}$
    be the linear form $f(x) = 2 x_1 - 3 x_2 + x_3$ and let $M$ be its 
    kernel. As in Example 2.5.9, think of $V/M$ as the set of planes consisting 
    of $M$ and the planes parallel to it. If $u$ and $v$ are two of these planes,
    their sum $u + v$ in $V/M$ can be visualized as follows: choose a point $P$
    on the plane $u$ and a point $Q$ on the plane $v$; add the arrows $OP$ and $OQ$
    using the parallelogram rule, obtaining an arrow $OR$; the plane through $R$ 
    parallel to $M$ is $u + v$.
\end{tcolorbox}

\textbf{Solution: } OK.

\begin{tcolorbox}[title=Problem 4, breakable]
    Let $M$ be a linear subspace of $V$, $u = x + M$ and $v = y + M$ 
    two elements of $V / M$.
    \begin{enumerate}
        \item Let $A = \{s + t \mid s \in u, t \in v\}$ be the sum of the sets $x + M$ and $y + M$
              in the sense of Definition 1.6.9. Then $A$ is also a coset, namely $A = x + y + M$.
              [This offers a definition of $u + v$ that is obviously independent of the vectors $x$ and $y$
              chosen to represent $u$ and $v$.]
        \item If $c$ is a nonzero scalar, then the set $B = \{cs \mid s \in u\}$ is a coset, 
              namely $B = cx + M$. What if $c = 0$?
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    Let $a$ be an arbitrary element in $A$ such that $a = s + t$.
    Suppose $s = x + m$ and $t = y + m'$ where $m, m' \in M$.
    Then taking sums we have $s + t = x + y + m + m'$.
    Now $m + m' \in M$ since $M$ is closed under addition.
    Thus $x + y + m + m' \in x + y + M$.

    Conversely, suppose $t \in x + y + M$ such that $t = x + 0 + y + m$.
    Then $0, m \in M$ thus $x + 0 \in x + M$ and $y + m \in y + M$ thus $t \in A$.
\end{proof}

\begin{proof}
    Suppose $c$ is a nonzero scalar.
    Let $b$ be an arbitrary element in $B$ such that $b = cs$ where $s \in u$.
    Suppose $s = x + m$ where $m \in M$. Then $b = cs = c(x + m) = cx + cm$.
    Now $cm \in m$ thus $b = cx + cm = cx + m \in cx + M$.

    Conversely, suppose $t$ is an arbitrary element in $cx + M$ such that $t = cx + m$ where $m \in M$.
     Now, $t = cx + m = cx + (0 + m)$ and $0 + m \in u$ thus $t \in B$.
\end{proof}

\textbf{Solution: } If $c = 0$ then $B$ is the set $\{0\}$.


\begin{tcolorbox}[title=Problem 5, breakable]
    Let $V$ be a vector space, $M$ and $N$ linear subspaces of $V$, and $x, y$ vectors in $V$.
    Prove:
    \begin{enumerate}
        \item $x + M \subset y + N$ if and only if $M \subset N$ and $x - y \in N$.
        \item $(x + M) \cap (y + N) \ne \emptyset$ if and only if $x - y \in M + N$.
        \item If $z \in (x + M) \cap (y + N)$ then $(x + M) \cap (y + N) = z + M \cap N$.
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    ($\longrightarrow$) Suppose $x + M \subset y + N$.
    Let $m$ be an arbitrary element in $M$.
    Since $x + m \in x + M$ and $x + M \subset y + N$ we have $x + m = y + n$ for some $n \in N$.
    Now let $m = 0$. Then $x = y + n \iff x - y = n \in N$.
    Now for arbitrary $m \in M$, we have $x + m = y + n$ for some $n \in N$, so $m = n - (x - y)$.
    Since $n \in N$ and $x - y \in N$ we have $m \in N$. Thus $M \subset N$ as required.

    ($\longleftarrow$) Suppose $M \subset N$ and $x - y \in N$.
    Let $t \in x + M$ such that $t = x + m$ for some $m \in M$.
    Since $M \subset N, x - y \in N$, we have $m \in N$ thus $t = y + ((x - y) + m) \in y + N$.
    Therefore $x + M \subset y + N$.
\end{proof}

\begin{proof}
    ($\longrightarrow$) Suppose $(x + M) \cap (y + N) \ne \emptyset$.
    Let $t \in (x + M) \cap (y + N)$ such that $t = x + m$ and $t = y + n$ for $m \in M$ and $n \in N$.
    Then $x + m = y + n \iff x - y = n - m \in N - M = M + N$.

    ($\longleftarrow$) Suppose $x - y \in M + N$. Then $x - y = m + n$ for some $m \in M$ and $n \in N$.
    Then $x - n = y + m$. Then $x - n \in x + N$ and $y + m \in y + M$ thus $x + N \cap y + M \ne \emptyset$.
\end{proof}

\begin{proof}
    Suppose $z \in (x + M) \cap (y + N)$.
    Then $z = x + m$ and $z = y + n$ for $m \in M$ and $n \in N$.
    Let $t$ be an arbitrary element in $(x + M) \cap (y + N)$.
    Then $t = x + m'$ and $t = y + n'$ for some $m' \in M$ and $n' \in N$.
    Then 
    \[t - z = (x + m') - (x + m) \in M,\]
    and 
    \[t - z = (y + n') - (y + n) \in N.\]
    Thus $t - z \in M \cap N$. Thus $t \in z + M \cap N$.
    Conversely, let $t \in z + M \cap N$.
    Then $t = z + m$ where $m \in M \cap N$.
    Thus $t \in x + M$ and $t \in x + N$ and therefore $t \in (x + M) \cap (y + N)$.
\end{proof}


\begin{tcolorbox}[title=Problem 6, breakable]
    Let $X$ be a nonempty set.
    Let $R$ be a subset of the cartesian product 
    $X \times X$, such that (i) $R$ contains the `diagnol'
    $X \times X$, that is, $(x, x) \in R$ 
    for all $x \in X$; (ii) $R$  is `symmetric in the diagnol',
    that is, if $(x, y) \in R$ then $(y, x) \in R$;
    and (iii) if $(x, y) \in R$ and $(y, z) \in R$ then 
    $(x, z) \in R$. Does this suggest a way of defining an equivalence
    relation $x \sim y$ in $X$.
\end{tcolorbox}

\textbf{Solution: } 
\[x \sim y \iff (x, y) \in R\]

\begin{tcolorbox}[title=Problem 7, breakable]
    Let $T : V \longrightarrow W$ be a linear mapping, $M$ a linear subspace of $V$ such that 
    $M \subset Ker T$, and $Q : V \longrightarrow V/M$ the quotient mapping. Prove:
    \begin{enumerate}
        \item There exists a (unique) linear mapping $S : V/M \longrightarrow W$ such that $T = SQ$ (Fig. 11).
        \item $S$ is injective if and only if $M = Ker T$.
    \end{enumerate}
\end{tcolorbox}

\begin{proof}
    Consider $S : V / M \longrightarrow W$ defined 
    \[
        S(x + M) = T(x).
    \]
    We first show $S$ is well defined. Suppose $x + M = y + M$.
    Therefore $x - y \in M$. Since $M \subset Ker T$,
    we have $T(x - y) = 0 \implies T(x) = T(y)$.
    Then let $x + M, y + M$ be arbitrary elements in $V/M$.
    Then 
    \[
        S((x + M) + (y + M)) = S(x + y + M) = T(x + y)
        = T(x) + T(y) = S(x + M) + S(y + M).
    \]
    Let $c$ be a scalar. Then 
    \[
        S(c(x + M)) = S(cx + M) = T(cx) = cT(x).
    \]
    Thus $S$ is a linear mapping.
    Now let $v$ be an arbitrary element in $V$.
    Then $(SQ)(v) = S(Q(v)) = S(v + M) = T(v)$.
    
    Suppose there exists $S'$ such that $S' : V/M \longrightarrow W$ and $T = S'Q$.
    For all $v \in V$ we have $T(v) = S'(Q(v)) = S(Q(v))$.
    Thus $S, S'$ agree at all cosets and therefore $S' = S$ and $S$ is unique.
\end{proof}

\begin{proof}
    Suppose $S$ is injective.
    We know $M \subset Ker T$ so let $t$ be an arbitrary element in $Ker T$.
    Then $T(t) = (SQ)(t) = S(t + M) = 0$.
    Since $S$ is injective we have $t + M = 0 + M$ thus $t \in M$. Thus $M = Ker T$.

    Suppose $M = Ker T$.
    Let $x + M$ be an arbitrary element in $V / M$.
    Suppose $S(x + M) = 0$.
    Then $T(x) = 0$ thus $x \in M$ and $S$ is injective.
\end{proof}

\begin{tcolorbox}[title=Problem 8, breakable]
    Let $M$ be a linear subspace of $V, Q: V \longrightarrow V/M$ the quotient mapping,
    $T : V \longrightarrow V$ a linear mapping such that $T(M) \subset M$. Prove that there 
    exists a (unique) linear mapping: $S : V/M \longrightarrow V/M$ such that $SQ = QT$ (Fig. 12).
    [Hint: Apply Exercise 7 to the linear mapping $QT : V \longrightarrow V/M$.]
\end{tcolorbox}

\begin{proof}
    Let $v$ be an arbitrary element in $M$.
    Since $T(M) \subset M$, we have $T(v) \in M$.
    Then $QT(v) = Q(T(v)) = 0$.
    Thus $M \subset Ker(QT)$.
    We can then apply Exercise 7 to find a linear mapping $S : V / M \longrightarrow V / M$
        such that $SQ = QT$.
\end{proof}

\subsection{The First Isomorphism Theorem}

\begin{tcolorbox}[title=Problem 1, breakable]
    When there's a first, there's a second.
    The following results is called the \emph{Second isomorphism theorem}.
    Let $V$ be a vector space, $M$ and $N$ linear subpsaces of $V$, $M \cap N$
    their intersection and $M + N$ their sum (1.6.9).
    Then $M \cap N$ is a linear subspace of $M$, $N$ is a linear subspace of $M + N$,
    and 
    \[M / (M \cap N) \cong (M + N) / N\]
    [Hint: Let $Q : V \longrightarrow V / N$ be the quotient mapping and let $T = Q \mid M$
    be the restriction of $Q$ to $M$ (Appendix 3.8), that is, $T : M \longrightarrow V / N$
    and $Tx = x + N$ for all $x \in M$. Show that $T$ has range $(M + N) / N$ and kernel $M \cap N$.]
\end{tcolorbox}

\begin{tcolorbox}[title=Problem 2, breakable]
    Let $M, N$ be linear subspaces of the vector spaces $V, W$ and let 
    \[T : V \times W \longrightarrow (V / M) \times (W / N),\]
    be the linear mapping defined by $T(x, y) = (x + M, y + N)$.
    Determine the kernel of $T$ and deduce another proof of 2.6, Exercise 2.
\end{tcolorbox}

\begin{tcolorbox}[title=Problem 3, breakable]
    Let $V$ be a vector space over $F$, $f : V \longrightarrow F$ a linear form on $V$ (Definition 2.1.11),
    $N$ the kernel of $f$. Prove that if $f$ is not identically zero, then $V / N \cong F$.
    [Hint: If $f(z) \ne 0$ and $c$ is any scalar, evaluate $f$ at the vector $(c / f(z))z$.]
\end{tcolorbox}

\begin{tcolorbox}[title=Problem 4, breakable]
    Let $V$ be a vector space, $V \times V$ the product vector space (1.3.11),
    and $\triangle = \{(x, x) \mid x \in V\}$ (called the \emph{diagnol} of $V \times V$).
    Prove that $\triangle$ is a linear subspace of $V \times V$ and that $(V \times V)/\triangle \cong V$.
    [Hint: 2.2, Exercise 4,]
\end{tcolorbox}

\begin{tcolorbox}[title=Problem 5, breakable]
    Let $N$ be the set of vectors in $\mathbb{R}^5$ whose last two coordinates are zero:
    \[N = \{x_1, x_2, x_3, 0, 0\} \mid x_1, x_2, x_3 \in \mathbb{R}.\]
    Prove that $N$ is a linear subspace of $\mathbb{R}^5$, $\mathbb{R}^3 \cong \mathbb{N}$, 
        and $\mathbb{R}^5 / \mathbb{N} \cong \mathbb{R}^2$.
    [Taking some liberties with the notation, $\mathbb{R}^5 / \mathbb{R}^3 = \mathbb{R}^2$.]
\end{tcolorbox}

\begin{tcolorbox}[title=Problem 6, breakable]
    Let $T$ be a set, $A$ a subset of $T$, $V = \mathcal{F}(T, \mathbb{R})$ and $W = \mathcal{F}(A, \mathbb{R})$
        the vector spaces of functions constructed in 1.3.4. Let $N$ be the set of all functions $x \in V$
        such that $x(t) = 0$ for all $t \in A$. Then $N$ is a linear subspace of $V$ and $V / N \cong W$.
    [Hint: Consider the mapping $x \mapsto x \mid A, (x \in V)$, where $x \mid A$ is the restriction 
    of the function $x$ to $A$ (Appendix A.3.8).]
\end{tcolorbox}